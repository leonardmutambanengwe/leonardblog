{
  
    
        "post0": {
            "title": "Cleaning webscrapped data and other messy text..",
            "content": "Cleaning webscrapped data can be a hassle, with html tags, urls, phone numbers, punctuation etc before doing text analysis. Clean-text promises to ease that burden considerably in one line of code, with flexibility regarding what one wants removed, or replaced. Whatsapp chats are also in the same region of difficulty in parsing as web data. I expoerted Data Science Zimbabwe group chats (there are 3 groups) to compare the themes most discussed in the respective groups using a wordcloud, after cleaning the texts. . # !pip install wordcloud # !pip install clean-text ###optional pip install clean-txt[gpl] . clean-text with gpl means it won&#39;t default to Python&#39;s unicodedata package, which apparently has worse results. (Worth checking the differences in a follow up to this post..) . import re import string import matplotlib.pyplot as plt %matplotlib inline from cleantext import clean from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator . Since the GPL-licensed package `unidecode` is not installed, using Python&#39;s `unicodedata` package which yields worse results. . We will use regex also to remove the time and number/contact text from a message. . with open(&#39;dsz13.txt&#39;, &#39;r&#39;, encoding=&#39;utf-8&#39;) as f: chats = f.readlines() . Not specifying the encoding will cause errors. . chats[:10] . [&#39;2021/08/17, 11:45 am - Messages and calls are end-to-end encrypted. No one outside of this chat, not even WhatsApp, can read or listen to them. Tap to learn more. n&#39;, &#39;2021/08/17, 11:45 am - You created group &#34;DataScienceZimbabwe&#34; n&#39;, &#34;2021/08/17, 11:54 am - +44 7592 754029 joined using this group&#39;s invite link n&#34;, &#34;2021/08/17, 12:05 pm - +263 78 489 2260 joined using this group&#39;s invite link n&#34;, &#34;2021/08/17, 12:10 pm - +263 77 408 0063 joined using this group&#39;s invite link n&#34;, &#34;2021/08/17, 12:13 pm - +263 77 578 6283 joined using this group&#39;s invite link n&#34;, &#39;2021/08/17, 12:25 pm - Evander DS joined using your invite n&#39;, &#34;2021/08/17, 12:27 pm - +263 71 880 8533 joined using this group&#39;s invite link n&#34;, &#34;2021/08/17, 12:41 pm - +263 77 231 5884 joined using this group&#39;s invite link n&#34;, &#34;2021/08/17, 12:47 pm - +263 78 376 9962 joined using this group&#39;s invite link n&#34;] . chats_ = [] for line in chats: line = re.sub(r&quot;[0-9]{4} /[0-9]{2} /[0-9]{2}, [0-9]+:[0-9]{2} [ap]m - .+:&quot;, &quot;&quot;, line) line = re.sub(r&quot; [[0-9]{2} /[0-9]{2}, [0-9]+:[0-9]{2} [AP]M] .+:&quot;, &quot;&quot;, line) if line.find(&#39;Messages and calls are end-to-end&#39;) == -1 and line.find(&#39;joined using this group &#39;s invite&#39;) == -1 and line.find(&#39;created group&#39;) == -1 and line.find(&#39;changed this group&#39;) == -1 and line.find(&#39;changed the group&#39;) == -1 and line.find(&#39;&lt;Media omitted&gt;&#39;) == -1 and line.find(&#39;left n&#39;) == -1 and line.find(&#39;changed to +&#39;) == -1 and line.find(&#39;joined using&#39;) == -1 and line.find(&#39;was added&#39;) == -1: chats_.append(line) . For each line read from the text file, search for the date, time and contact/number and replace. Also replies to a message have a date and time part that needs to be removed. | Remove the lines which are system messages, including creation of group, joining, editing and deletion of messages etc. | append to an empty list | . chats_[:10] . [&#39; Good for practitioners as well n&#39;, &#39; *Investors, Randomness, and Entrepreneurial Thinking* n&#39;, &#39;https://mises.org/wire/investors-randomness-and-entrepreneurial-thinking n&#39;, &#39; n&#39;, &#39;TAGS Financial MarketsMedia and CultureCalculation and Knowledge n&#39;, &#39; n&#39;, &#39;LEE ESTO EN ESPAÑOL n&#39;, &#39;01/07/2020Joakim Book n&#39;, &#39;Imagine mailing a stock prediction for next week to ten thousand unknowing recipients. Half of them contain a prediction for rising prices of some instrument, and the other half contain a gloomy forecast for the same stock. The following week you repeat the same exercise with the half for whom you happened to be right. After ten weeks, your initial sample has dwindled to nine people — but for them, you increasingly look like a stock market genius. For ten weeks straight you correctly predicted the movement of a given stock. n&#39;, &#39; n&#39;] . chats_ = clean(chats_, fix_unicode=True, to_ascii=True, lower=True, no_emails=True, no_urls=True, no_line_breaks=True, no_phone_numbers=True, no_numbers=True, no_punct=True, replace_with_url=&#39;URL&#39;) chats_[:1000] . &#39;good for practitioners as well investors randomness and entrepreneurial thinking url tags financial marketsmedia and culturecalculation and knowledge lee esto en espanol &lt;number&gt;&lt;number&gt;2020joakim book imagine mailing a stock prediction for next week to ten thousand unknowing recipients half of them contain a prediction for rising prices of some instrument and the other half contain a gloomy forecast for the same stock the following week you repeat the same exercise with the half for whom you happened to be right after ten weeks your initial sample has dwindled to nine people but for them you increasingly look like a stock market genius for ten weeks straight you correctly predicted the movement of a given stock this problem is known variously as the baltimore stockbroker scam the file drawer problem or publication bias all illustrating that with large enough samples even chance will look suspiciously nonrandom a chosen outlier ten correct calls in a row may look impressive to the sele&#39; . Running clean() on the chats, removes numbers, emails, urls, punctuation, returns lowercase and removes line breaks, leaving the text data almost perfect for analysis. A bit more cleaning may be required for a few situations in which other things maybe missed . clean = &quot;&quot;.join([i for i in chats_ if i not in string.punctuation+&#39;“&#39;+&#39;”&#39;+&#39;’&#39;]) . A more surer way to remove punctuation. It seems the clean() function misses some punctuation like &#39;+&#39;. . clean[:1000] . &#39;good for practitioners as well investors randomness and entrepreneurial thinking url tags financial marketsmedia and culturecalculation and knowledge lee esto en espanol numbernumber2020joakim book imagine mailing a stock prediction for next week to ten thousand unknowing recipients half of them contain a prediction for rising prices of some instrument and the other half contain a gloomy forecast for the same stock the following week you repeat the same exercise with the half for whom you happened to be right after ten weeks your initial sample has dwindled to nine people but for them you increasingly look like a stock market genius for ten weeks straight you correctly predicted the movement of a given stock this problem is known variously as the baltimore stockbroker scam the file drawer problem or publication bias all illustrating that with large enough samples even chance will look suspiciously nonrandom a chosen outlier ten correct calls in a row may look impressive to the selected&#39; . tokens = chats_.split(&#39; &#39;) tokens[:20] . [&#39;good&#39;, &#39;for&#39;, &#39;practitioners&#39;, &#39;as&#39;, &#39;well&#39;, &#39;investors&#39;, &#39;randomness&#39;, &#39;and&#39;, &#39;entrepreneurial&#39;, &#39;thinking&#39;, &#39;url&#39;, &#39;tags&#39;, &#39;financial&#39;, &#39;marketsmedia&#39;, &#39;and&#39;, &#39;culturecalculation&#39;, &#39;and&#39;, &#39;knowledge&#39;, &#39;lee&#39;, &#39;esto&#39;] . World cloud generation and visualisation . Stopwords will overwhelm any text corpora, and so it is standard to remove them. The group chats being analysed here had chain texts with repeating words, which words had to be removed from the text. So the list of stop words was updated with these words. . stopwords = set(STOPWORDS) stopwords.update([&#39;will&#39;, &#39;u&#39;, &#39;doesnt&#39;, &#39;hi&#39;, &#39;im&#39;, &#39;number&#39;, &#39;thank&#39;, &#39;url&#39;, &#39;etc&#39;, &#39;sherilyn&#39;, &#39;maphosa&#39;, &#39;henrica&#39;, &#39;makhuku&#39;, &#39;ruvimbo&#39;, &#39;mambinge&#39;]) . wordcloud = WordCloud(stopwords=stopwords, background_color=&quot;white&quot;).generate(clean) . plt.figure(figsize=[20, 10]) plt.imshow(wordcloud, interpolation=&#39;bilinear&#39;) plt.axis(&quot;off&quot;) plt.show() . wordcloud = WordCloud(stopwords=stopwords, background_color=&quot;white&quot;).generate(clean) . plt.figure(figsize=[20, 10]) plt.imshow(wordcloud, interpolation=&#39;bilinear&#39;) plt.axis(&quot;off&quot;) plt.show() . wordcloud = WordCloud(stopwords=stopwords, background_color=&quot;white&quot;).generate(clean) . plt.figure(figsize=[20, 10]) plt.imshow(wordcloud, interpolation=&#39;bilinear&#39;) plt.axis(&quot;off&quot;) plt.show() . The 3 wordclouds generated for the 3 groups are as shown above. With the words most included in discussions shown by the size of the word in the wordcloud. Interesting to note that the 1st group has more diverging conversation from data science whilst the other 2 stick more to the field. The data would probably need a bit more cleaning, as the package didn&#39;t comprehensively deal with urls, maybe because it removes punctutation first and so then urls just become words. So it would also be prudent to follow up on that aspect. .",
            "url": "https://leonardmutambanengwe.github.io/leonardblog/2022/03/30/Cleaning-text-data-using-clean_text.html",
            "relUrl": "/2022/03/30/Cleaning-text-data-using-clean_text.html",
            "date": " • Mar 30, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "Functions in Julia with more image processing and transformations",
            "content": "In this write up . write function to allow user to input a kron factor, scaling value (and also convex optimisation) | Downsampling, upsampling, | Offset index | More image processing using custom function for edge detection and ImageFiltering&#39;s imfilter.. | N0f8/16/32/64 data type | . begin using Images, Colors, ColorVectorSpace, ImageShow, FileIO, ImageIO using ImageFiltering using OffsetArrays using Plots end . pexels = load(&quot;./images/pexels-photo-2422290.jpeg&quot;) . size(pexels) . (750, 1042) . Downsampling . By taking only some pixels of the image, we get a lower resolution of the original image (reducing storage size). . pexels_downsample = pexels[1:3:end, 1:4:end] . size(pexels_downsample) . (250, 261) . The original image which was of size 750x1042 has now been reduced to 250x261 by taking every 3rd pixel of the rows and every 4th pixel of the columns. . Upsampling is the inverse and will just add more pixels to an image. How to upsample is the interesting bit, it is not as simple as just picking which pixel to keep, however there are many ways of upsampling. . We can upsample an image by multiplying the matrix array by a square matrix using the Kronecke product. A matrix of mxn multiplied by a square matrix of pxp will result in an (mxp)x(nxp) array which is the upsampled image. . In Julia, this can be achieved by using the kron function, whose arguments are the two arrays, which in our case are the image and a square matrix of 1s. . pexels_upsample = kron(pexels_downsample, fill(1, 3, 4)) . fill(1, 3, 4) . 3×4 Matrix{Int64}: 1 1 1 1 1 1 1 1 1 1 1 1 . size(pexels_upsample) . (750, 1044) . Functions in Julia . 3 ways of writing functions: . The short form | &emsp;&emsp;f(a) = a * a . The anonymous form | &emsp;&emsp;x -&gt; sin(x) . The block form | &emsp;&emsp;function func(x, y) &emsp;&emsp;&emsp;x + y, |x - y| . &emsp;&emsp;end . &emsp;(return is optional) . Writing a function that will pass 2 arguments to a function, m and n dimensions of a matrix of 1s that will be used to kron upsample an image. . Notes: . dim1 is a keyword argument, used as a label (separated from the unlabelled arguments with a semi-colon) | n will default to dim1 if only one additional argument to image is specified, creating a square matrix. | function upsample(image; dim1=m, n=dim1) kron(image, fill(1, dim1, n)) end . upsample (generic function with 1 method) . methods(upsample) . # 1 method for generic function upsample: upsample(image; dim1, n) in Main at c: Users Leonard Work Julia Images_Transformations_Abstractions images2.ipynb:1 | . The methods function gives more information about a particular function . cat = load(&quot;./images/cat.jpg&quot;) . upsample(cat, dim1=3, n=4) . upsample(cat, dim1=5) . Linear transformations . Scaling is a linear transformation in which a scalar multiplies the image. . c = 0.5 c .* cat #the dot is indicating that the scalatr is being broadcast to every pixel of the image . The cat picture has visibly become dull. . 0.01 .* cat . 3 .* cat . As c goes to 0, the picture becomes darker, whereas as c goes beyond 1, the picture saturates... . Combining two or more images, by simply adding the arrays of the images together. . upside_cat = cat[end:-1:1, :] . mixed_cat = cat + upside_cat . Convex combination where α and β used to scale the two mixed images add up to 1 . .5 .* cat + .5 .* upside_cat . Write a function that takes α and does a convex transformation of two provided images . function ConvexTransform(image1, image2, α) α .* image1 + (1 - α) .* image2 end . ConvexTransform (generic function with 1 method) . ConvexTransform(pexels, pexels[end:-1:1, :], 0.39) . Many image processing functions use grayscale images, converting to grayscale in Julia... . colorview(Gray, Gray.(cat)) . Edge detection . edge_detect = [0 -1 0; -1 4 -1; 0 -1 0] . 3×3 Matrix{Int64}: 0 -1 0 -1 4 -1 0 -1 0 . We want to convolve the cat image with the edge detect kernel. Moving the kernel across the pictures, multiplying elementwise and returning the sum, which then becomes the new value of the pixel. . function EdgeDetect(image, filter; padding=0) img_gray = channelview(Gray.(image)) temp = fill(0N0f8, height(img_gray)+2*padding, width(img_gray)+2*padding) temp[padding+1:end-padding, padding+1:end-padding] = img_gray convolved = fill(0.0, height(img_gray)-height(filter)+1+2*padding, width(img_gray)-width(filter)+1+2*padding) for i in 1:1:height(temp)-height(filter)+1 for j in 1:1:width(temp)-width(filter)+1 a = sum(temp[i:i+height(filter)-1, j:j+width(filter)-1] .* filter) convolved[i, j] = a end end return colorview(Gray, convolved) end . EdgeDetect (generic function with 2 methods) . The function takes as arguments, an image, a filter and a padding value (defaults to 0) and is implemented as follows: . Convert the image to grayscale | Create temporary array of zeros with added rows and columns to represent padding around the image. | To the temporary array, superimpose the gray image, by replacing the 0s with values from the gray image leaving 0s at the outer rows and columns, the padding. | Create another temporary array, whose values will be replaced with the new pixel values as the filter moves across the image. | Return the filtered image | EdgeDetect(cat, edge_detect, padding=1) . leo = load(&quot;./images/leo.jpg&quot;) . EdgeDetect(leo, edge_detect) . Or you could just use the imfilter function from the ImageFiltering package... . imfilter(cat, edge_detect) . function FilterImage(image, filter; padding=0) img_array = reshape(channelview(image), height(image), width(image), 3) temp = fill(0N0f8, height(img_array)+2*padding, width(img_array)+2*padding, 3) temp[padding+1:end-padding, padding+1:end-padding, :] = img_array convolved = fill(0.0, height(image)-height(filter)+1+2*padding, width(image)-width(filter)+1+2*padding, 3) for k in 1:1:3 for i in 1:1:height(temp)-height(filter)+1 for j in 1:1:width(temp)-width(filter)+1 a = sum(temp[i:i+height(filter)-1, j:j+width(filter)-1, k] .* filter) convolved[i, j, k] = a end end end return colorview(RGB, reshape(convolved, (3, height(convolved), width(convolved)))) end . FilterImage (generic function with 2 methods) . Trying out other filters using imfilter.. . sharpen = [0 -1 0; -1 5 -1; 0 -1 0] . 3×3 Matrix{Int64}: 0 -1 0 -1 5 -1 0 -1 0 . imfilter(cat, sharpen) . Built-in filters.. . imfilter(cat, Kernel.gaussian(3)) . imfilter(cat, Kernel.Laplacian()) . Other filters that are available for use with imfilter . sobel | prewitt | ando3, ando4, and ando5 | scharr | bickley | DoG (Difference-of-Gaussian) | LoG (Laplacian-of-Gaussian) | gabor | moffat | . Offsetting . Julia can allows arbitrary indexing (instead of starting at 1 (default) or 0 (Python)). Can be very useful in dealing with arrays,especially multi-dimensional ones. . M = collect(1:10) OffM = OffsetArray(M, -5:4) . 10-element OffsetArray(::Vector{Int64}, -5:4) with eltype Int64 with indices -5:4: 1 2 3 4 5 6 7 8 9 10 . println(OffM[-5]) println(OffM[-2]) println(OffM[4]) . 1 4 10 . Off = [1 2 2; 3 5 3; 2 6 5] OffCentered = OffsetArrays.centered(Off) . 3×3 OffsetArray(::Matrix{Int64}, -1:1, -1:1) with eltype Int64 with indices -1:1×-1:1: 1 2 2 3 5 3 2 6 5 . OffsetArrays.center(Off) . (2, 2) . N0f8/16/... . When processing images, the array can be stored in this format which is a normalised (between 0 and 1) which makes image processing handy. Can be manipulated to result in floats (like mulitiplication and summing in filters or convolutions) . x = fill(0.0N0f8, 3, 3) . 3×3 Array{N0f8,2} with eltype N0f8: 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 . x[1, 1] . 0.0N0f8 . dump(x[1, 1]) . N0f8 i: UInt8 0x00 . y = channelview(cat)[1, 6, 3] . 0.016N0f8 . dump(y) . N0f8 i: UInt8 0x04 . float(y) . 0.015686275f0 .",
            "url": "https://leonardmutambanengwe.github.io/leonardblog/2022/01/16/Functions-with-Julia-Image-Processing.html",
            "relUrl": "/2022/01/16/Functions-with-Julia-Image-Processing.html",
            "date": " • Jan 16, 2022"
        }
        
    
  
    
        ,"post2": {
            "title": "A Year of Pumpkin Prices A regression with Knime",
            "content": "KNIME Analytics is a low code platform for analytics, in which visual programming paradigm is implemented through the use of workflows. Nodes representing actions on data are linked, sequentially, as a DAG. A Year of Pumpkins dataset has information about the prices of pumpkins for months in 2016 and 2017, as well as other information including packaging, sizes, type for 13 different cities in the USA. . The dataset is actually made up of multiple datasets, each for a separate city. Using the CSV Reader node, all 13 files could be read at once. However, because some of the files had more columns, an option to catch the error had to be relaxed. The columns are as below: . . The last 4, are not in most of the other csv files, and so had to be removed using the Column Filter node. Other columns with no valuable information were also removed, as well acolumnss those with over 40% missing values with Missing Value Column Filter node. . Column Date was transformed into datetime, using Pandas. Knime can integrate python (and other languages including R and Java). The date was then used to access, using dt, week, month and week information which might be useful in determining price levels. Also the average price was calculated from low and high for the day. . . The linear regression is a base line to benchmark the performance. The data was split 70:30 using the Partitioning node, and a Linear Regression Learner and Linear Regression Predictor were used to train and predict on the test set. The regression was run on 11 columns. . Results of the linear regression, including R-squared for model fit and RMSE for performance. . Linear correlation was used to remove corelated features. 2 columns were removed and training and predict done. . . Removing the correlated features resulted in a slight improvement in the RMSE, falling to 41.293 from 42.04. . Whole workflow . Other ideas to explore: . H2o regression and tree regression - to explore feature importances | Regularisation methods for regresssion - LASSO, Ridge | SVM | Packaging - there are different packages measurements, see if they can be standardised. | Visualisations |",
            "url": "https://leonardmutambanengwe.github.io/leonardblog/2022/01/05/A-Year-of-Pumpkin-Prices-Regression-with-Knime.html",
            "relUrl": "/2022/01/05/A-Year-of-Pumpkin-Prices-Regression-with-Knime.html",
            "date": " • Jan 5, 2022"
        }
        
    
  
    
        ,"post3": {
            "title": "Getting started with arrays in Julia using images",
            "content": "Julia has been touted as the next best thing in computational programming, potentially replacing fan favourite, Python, as the go to language for data science and machine learning. . . I have been looking to learn Julia for some time, and have finally gathered the courage to begin, following the MIT&#39;s 2021 Computational Thinking course, JuliaImages documentation and Tutorialspoint tutorial. The hope is to use Julia for quantitative economics, agent-based models and related interests (and some data science and machine learning of course!). . Some introductory concepts like installation, environments, packages and variables I have skipped to dive into the language. The Tutorialspoint tutorial gives quite good explanations for these. . Arrays are key to computational work, providing the building blocks for programming work in data science and machine learning. In this piece, I will use images to explore arrays. An array in Julia is a set of items &quot;specified with square brackets&quot; that can contain similar items or different items. . Creating arrays... | arr = [1,2,3] . 3-element Vector{Int64}: 1 2 3 . arr1 = [&quot;Leonard&quot;, tan, RGB(0, 1, 1, 1.245)] . Array[1:10] . 1-element Vector{Array}: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] . arr2 = Array{Int64}(undef, 2, 2) #Create a 2x2 array with undefined values of type Integer64 . Array[1:5,5:9] . 2-element Vector{Array}: [1, 2, 3, 4, 5] [5, 6, 7, 8, 9] . collect(1:2:20) . 10-element Vector{Int64}: 1 3 5 7 9 11 13 15 17 19 . arr3 = collect(range(1, 15, 30)) . 30-element Vector{Float64}: 1.0 1.4827586206896552 1.9655172413793103 2.4482758620689653 2.9310344827586206 3.413793103448276 3.896551724137931 4.379310344827586 4.862068965517241 5.344827586206897 ⋮ 11.137931034482758 11.620689655172415 12.10344827586207 12.586206896551724 13.068965517241379 13.551724137931034 14.03448275862069 14.517241379310345 15.0 . Collect uses (start:step:stop) format whilst range uses (start, stop, length). . [1:10...] #using the ellipses . 10-element Vector{Int64}: 1 2 3 4 5 6 7 8 9 10 . A matrix can be created by specifying the arrays, separating the rows with a semi-colon (;) . matrix = [[1 2];[3 4]] . 2×2 Matrix{Int64}: 1 2 3 4 . Compare with.. . arr4 = [[1 2], [3 4]] . 2-element Vector{Matrix{Int64}}: [1 2] [3 4] . tensor = Array{Float32}(undef, 3, 3, 3) . 3×3×3 Array{Float32, 3}: [:, :, 1] = 0.0 0.0 4.0f-45 0.0 3.0f-45 0.0 1.0f-45 0.0 6.0f-45 [:, :, 2] = 0.0 7.0f-45 0.0 7.0f-45 0.0 1.0f-44 0.0 1.0f-44 0.0 [:, :, 3] = 1.3f-44 0.0 6.0f-45 0.0 1.5f-44 0.0 1.3f-44 0.0 1.8f-44 . Manipulating arrays.. | These functions change the array in place, nota bene. . push!(arr, 10) . 4-element Vector{Int64}: 1 2 3 10 . pushfirst!(arr, 27) . 5-element Vector{Int64}: 27 1 2 3 10 . splice!(arr, 3, 12) . 2 . pop!(arr) . Arrays with images | using Images #importing a package (use add Package to install the package) . path_to_image = &quot;.. images Brain-Teaser2.png&quot; img = load(path_to_image) . Julia, in the notebook automatically shows the read image. Cool! Also Julia strings are double quotes ONLY, nota bene. . size(img) . (578, 1255) . img[100, 200] . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; . RGB(0, 0, 1) . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; Another really cool feature from Julia. Can you do this in Python? . brain = img[100:470, 350:900] . save(&quot;.. images brain.png&quot;, brain) . All errors: =========================================== Could not open . imagesrain.png for writing =========================================== WriteBlob Failed `. imagesrain.png&#39; @ error/png.c/MagickPNGErrorHandler/1641 =========================================== SystemError: opening file &#34;. images brain.png&#34;: Invalid argument =========================================== . Errors encountered while save FileIO.File{FileIO.DataFormat{:PNG}, String}(&#34;. images brain.png&#34;). Fatal error: . 0 . The save function worked, but why it threw those errors, I am not sure yet. Errors in Julia I haven&#39;t yet grasped. Still yet to see a language with helpful error messages! . Kaleidoscope The last element of an array is &quot;end&quot; compared to -1 in python . [ img img[:, end:-1:1] img[end:-1:1,:] img[end:-1:1, end:-1:1] ] . size(pex) . (750, 1042) . imgc = rand(RGB{Base.Float32}, 3, 3) . dump(imgc) #dump gives the internal representation of an object . Array{RGB{Float32}}((3, 3)) 1: RGB{Float32} r: Float32 0.11253506f0 g: Float32 0.55760473f0 b: Float32 0.27864915f0 2: RGB{Float32} r: Float32 0.18111825f0 g: Float32 0.28725207f0 b: Float32 0.9795578f0 3: RGB{Float32} r: Float32 0.28679127f0 g: Float32 0.43194884f0 b: Float32 0.5378687f0 4: RGB{Float32} r: Float32 0.4753642f0 g: Float32 0.035165608f0 b: Float32 0.88715f0 5: RGB{Float32} r: Float32 0.4875096f0 g: Float32 0.20408314f0 b: Float32 0.01918888f0 6: RGB{Float32} r: Float32 0.18497908f0 g: Float32 0.1815986f0 b: Float32 0.276653f0 7: RGB{Float32} r: Float32 0.67196274f0 g: Float32 0.4420526f0 b: Float32 0.50409055f0 8: RGB{Float32} r: Float32 0.44515795f0 g: Float32 0.70845145f0 b: Float32 0.99803203f0 9: RGB{Float32} r: Float32 0.4571224f0 g: Float32 0.5548946f0 b: Float32 0.38366348f0 . imgc[2,3] . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; dump(imgc[2,3]) . RGB{Float32} r: Float32 0.44515795f0 g: Float32 0.70845145f0 b: Float32 0.99803203f0 . c = imgc[2,3]; (red(c), green(c), blue(c)) . (0.44515795f0, 0.99803203f0, 0.70845145f0) . [RGB(x, 1, 1) for x in 0:0.1:1.0] . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; [ RGB(x, y, 1) for x in 0:0.1:1.0, y in 0:0.1:1.0 ] . Other cool things in Julia to do with images. To be explored more in a later post. Mosaicview makes it easy to juxtapose images, or stack them. Rot180 and reverse are self explaining. . pex = load(&quot;./images/pexels-photo-2422290.jpeg&quot;) . mosaicview(img, pex) . mosaicview(img, pex; nrow=1) . rot180(img) . reverse(pex) . Synthetic images using random numbers | img_gen = randn(300, 250, 3) . 300×250×3 Array{Float64, 3}: [:, :, 1] = -0.600125 -1.56632 -0.312504 … -0.103091 -0.271007 -1.13409 0.244688 1.25623 0.259431 -0.636025 -0.208713 0.315366 -1.22143 -0.59499 0.604384 -0.116677 1.16373 -0.0722718 -0.622335 -1.08539 -0.724112 0.609908 -0.0189383 -0.128967 1.35767 1.31528 -0.249722 -1.36404 -0.293069 0.556582 0.534793 1.27606 -0.154081 … 1.12524 0.552972 1.02783 0.319008 0.00880301 0.220965 1.11737 0.779357 -0.309602 -0.362791 -1.31784 -0.253949 0.353058 -0.453932 -0.574562 -0.120969 -0.962137 1.34985 2.07872 -0.94339 -0.0697277 0.0511402 -1.99099 0.736905 1.61943 2.2774 -0.513229 ⋮ ⋱ -0.323872 -0.181434 1.12721 -1.13482 0.335018 0.868675 0.603353 -0.606318 0.939072 0.048147 0.316767 0.275852 0.977469 -1.24712 -1.44946 0.3013 -1.0562 -0.800215 2.2684 1.51708 0.621769 1.23412 0.656476 0.201373 -0.136838 0.634701 -0.215518 … -0.201611 -2.17347 1.6066 -1.24558 0.0652409 0.0804678 -0.854146 -0.578367 1.92466 2.00107 -0.596724 1.53221 1.57971 0.84556 -0.47681 -0.439637 -0.196832 -1.69774 -0.5361 -0.582335 1.0349 -0.304142 -0.622998 -1.41491 -0.600071 2.76946 0.676878 [:, :, 2] = -1.07388 -0.605201 -0.213867 … 0.853067 -0.291855 -2.45098 0.129474 -0.121532 1.2076 -0.0610356 -2.04145 0.00149836 1.27809 0.779509 0.640596 1.35758 0.450349 2.08358 0.0636016 1.07457 0.0605442 0.110871 -1.66489 1.3797 -0.244607 -0.307671 0.357756 -0.436152 0.438603 0.0740943 1.25962 0.742925 0.38487 … -0.720242 -0.586007 0.440213 -1.36131 1.45913 -1.26939 -0.3846 -0.570169 -0.0160573 0.754807 1.03674 -0.443173 0.468278 0.892556 -0.586991 -1.77824 0.839453 -1.48134 -1.22049 0.279893 1.58792 1.0486 0.604839 -0.161788 0.292014 -1.75065 0.67918 ⋮ ⋱ 1.94354 -1.4899 -0.300526 -2.11149 -0.536682 1.23141 -1.80439 -0.384776 -1.01934 -0.31576 -0.743674 -0.735456 -2.11735 -0.409913 -0.147772 0.604897 -0.416731 -0.3253 0.117426 -0.591422 -1.71241 -1.42072 1.67098 2.64896 -0.0323333 1.05344 -1.36912 … -0.0445616 -1.00345 1.59313 -0.265179 0.501541 -2.47764 -1.71942 -0.628153 0.0107511 0.630664 0.191456 0.291961 0.770989 0.470247 -0.239118 -0.0167329 -1.78455 -1.55999 -1.14523 -1.08318 -0.506993 -2.39033 -0.799303 -0.51274 0.0174815 -0.31149 0.127548 [:, :, 3] = 0.140216 -0.485375 0.267151 … -0.385111 2.16931 -0.353331 -0.561392 -0.841544 1.90666 -1.6451 0.416531 -0.564599 -0.0901542 0.617174 1.20817 -0.698607 -0.0417566 0.0464137 1.02936 0.509171 -1.35276 -1.0066 1.54414 -0.0431321 0.697595 0.639903 0.150722 0.468857 -1.11395 1.33858 -0.923934 0.232699 1.3056 … -0.142713 -1.5119 -0.223377 -0.989095 -0.255251 0.0348486 -0.721624 -2.00278 0.331685 -0.0124481 1.52724 1.43884 0.267863 1.34697 -1.29293 0.0802858 0.395102 -0.0679597 1.22957 -0.0325846 0.949232 -0.324235 0.555573 1.09 0.254719 1.37643 1.80199 ⋮ ⋱ 1.12088 0.120046 0.199124 -0.982841 -0.692224 -1.05452 0.312383 0.0519733 0.258929 0.843973 0.714431 -1.20695 -1.27403 -0.639111 -3.03254 -1.10927 0.723798 0.0525366 0.861625 -0.698227 -1.35669 1.3572 0.399639 -0.0544047 0.144619 0.807803 -0.733975 … -1.10102 -0.401426 0.574467 -0.203666 -0.848899 0.0437872 -0.637434 0.122017 -0.475935 -0.843858 0.189737 -0.0541529 -1.96681 1.76856 -0.518815 1.378 0.342705 1.2765 0.018891 0.833686 0.344957 -0.105764 -0.368011 0.23163 0.917879 0.243322 0.616008 . colorview(RGB, reshape(img_gen, 3, 300, 250)) . colorview(RGB, reshape(img_gen, (3, 250, 300))) .",
            "url": "https://leonardmutambanengwe.github.io/leonardblog/2022/01/03/Getting-Started-with-Arrays-in-Julia-with-Images.html",
            "relUrl": "/2022/01/03/Getting-Started-with-Arrays-in-Julia-with-Images.html",
            "date": " • Jan 3, 2022"
        }
        
    
  
    
        ,"post4": {
            "title": "Filling the void",
            "content": "Looking out of the window, on a moody January morning, it is hard to tell how I got here. It is 2021, and it seems the hopes for a better 2021 have not started to bear fruit, with the pandemic raging more than ever, outisde in the world. Infections and deaths are up, many countries hitting record highs, eclipsing the first wave figures. But life has to go on. We live day by day. . It has been a good 2+ years since I have written anything, and this post, as titled, is to fill that gap and give a perspective on the road ahead. I guess it also refers to the perspective itself. I feel this an effort to rise to some occassion, and that I can only do by admitting that I had lost my way, somewhere along the road. . I remember, 2018 felt great. Completed my qualification, spoke at my first conference, constituted Data Science Zimbabwe and we had our first meet up and I was looking forward to taking my first real venture, Peachgrove, an horticultural produce and marketing venture, off the ground. Everything felt good. The sky was the limit. But Zimbabwe is not an easy country, and the hope of the reset in 2017 (despite the same honchos still running the country) faded and all illusions disappeared quite fast. Having to build up and get things running in a volatile environment meant the horticultural venture would really not translate to anything except lessons. Lessons that will be valuable in anything I attempt going forward and still one day, I certainly hope to explore the venture, to start again, for I feel it is a part of my being. . Along the road, another venture came up. Quantum Analytica, a data analytics-marketing-systems development outfit. The prospects looked great. We had initial contact with multiple clients, the appetite for our services seemed bottomless. The discussions were amazing, the founding team even more so. But maybe because I was still holding on to Peachgrove, hoping that I can find a way out of the malaise it was suffering, and Quantum Analytica seemed to be able to play a role in that. But it also fell apart. The environment in Zimbabwe has impacted a lot of things for entrepreneurs. The volatility impacting the effectiveness of any resources, but nothing is more poignant than the impact on the people resources. It becomes to hard to get people to buy in into any entrepreneurial venture. It definitely is not unexpected given the situation. It still makes it hard. And so we found ourselves having to shelf a good opportunity. And I went back to farming… . All the while, Data Science Zimbabwe has been chugging along, quietly in the background. DSZ was created as a means to provide a platform to bring together Zimbabweans interested in data and data-based solutions together. And we managed to get the interest going in a short time. I am so grateful to the community for making up a vibrant community. Operating on a zero revenue budget, there has been more done within the organization that I could have thought in 2018, beginning the journey. And it has been my ray of hope, as everything else seemed untenable, the prospect of making an impact is very humbling and satisfying. And even in 2020 when the pandemic threatened everything else, the community kept on, engaging over Whatsapp, participating in hackathons, and I can definitely say for the near future, it is my main consideration and I hope 2021 sees the community grow in leaps and bounds, and initiatives lead to visibility for the community at the forefront of the 4th Industrial Revolution in Zimbabwe. . So 2021 is here. And the hope is that for the lessons learnt in the past 2 years, and the new normal that is being hashed out by the pandemic, resilience and taking care of opportunities that present themselves are the order of the day to fill that void and get back to the unfettered hope that coursed these veins in 2018. . Let’s go!!!! I am up for it. .",
            "url": "https://leonardmutambanengwe.github.io/leonardblog/2021/01/14/Filling-the-void.html",
            "relUrl": "/2021/01/14/Filling-the-void.html",
            "date": " • Jan 14, 2021"
        }
        
    
  
    
        ,"post5": {
            "title": "Back to Africa ..and of conferences and travel documents",
            "content": "So I have been back from Italy for close to 75 days now, and it has mostly been chilling, watching television and catching up with family. I have also put in a number of applications with some local companies for data science jobs and had a grand total of ZERO responses. My closest bet at the moment is a company that does not know whether to put me under IT or Finance departments. But that is the situation in South Africa currently, with the onset of economic problems and perennial youth unemployment. Worse still, I am Zimbabwean in South Africa, job issues are always to be expected. So what to do? . In February 2018 I, with others, started a group called Data Science Zimbabwe that we hope can be a platform for people in data-related professions and academia to lead the 4th Industrial Revolution in Zimbabwe. We have only so far communicated via WhatsApp, but I am hopeful of the prospects. I am hoping we can have our first meet-up soon and start putting together a solid foundation for the advancement of data science and machine and deep learning as well as Artificial Intelligence in Zimbabwe. So for the time being, that is what my data science path has led me to and I am relishing the challenge. . I have also done a talk proposal for PyCon Zimbabwe on Agent-based modeling and Network Analysis using MESA and NetworkX, hopefully the experience is positive and provides an opportunity to make Data Science Zimbabwe visible within the tech community. This leads me to an important topic, that impacted me personally and have seen general discussions about on social media as well, globally. The choice of venues for conferences. . The Deep Learning Indaba was set for Stellenbosch University in South Africa. This is an important conference, in terms of my field and is important that participation, especially from Africans, show that the field is alive and kicking on the continent. However, South Africa is one of the hardest countries to get immigration documents for on the continent, especially to fellow Africans. I know the topic of holding conferences in countries that are inclusive is not new, and has gained traction in light of the trends in geopolitics in Europe and America. And here in Africa it is of no less concern. I was heartbroken when I saw a tweet about someone who had been given the whole funding to attend the conference, on condition they got their documents for travel to South Africa sorted out. No prize for guessing the outcome of their application. . Is Africa ready for full on co-operation in cutting edge fields that transcends borders? Can we get the academics, practitioners, experts etc in the same room, without hassle about movement from country A to country B? Should these types of conferences, be it in our field or any other, be held in countries that make it hard for those from other countries to travel there and be a part of these important get-togethers. These are the kind of matters that will affect Africa’s ability to embrace advancements in any area and be able to build lasting solutions to problems on our continent. I feel sorry for anyone who would have wanted to attend this conference and has to live with Twitter updates and Github practicals. . Rwanda has done Africa a solid with their changes to requirements for travel to the country, for Africans. This is a move to be applauded. But at this moment, I would tip my hat to any country on the continent that will suspend its (obviously) rigid, red tape surrounding movement for academic or professional conferences and gatherings and get-togethers, because if Africa is going to progress, we need to have great minds together as frequently as possible. This will help create networks all over the continent, not hindered by the travel requirements and a solid hope for the getting a lot of work done and catching up to global levels of progress in many fields. . I hope one day Africa will not let colonial demarcations hamper the progress of its people, and we will see the free flow of knowledge from Cape to Cairo. .",
            "url": "https://leonardmutambanengwe.github.io/leonardblog/2018/09/14/Back-to-Africa-/and-of-conferences-and-travel-documents.html",
            "relUrl": "/2018/09/14/Back-to-Africa-/and-of-conferences-and-travel-documents.html",
            "date": " • Sep 14, 2018"
        }
        
    
  
    
        ,"post6": {
            "title": "Welcome!",
            "content": "This is a log of activities and expected for the year commencing from my return to the Motherland. I hope I can look at it in one year and make an informed decision about the next steps I want to take. It will also have, general blog posts, on matters of interest, especially techpreneurship and general economics commentary. So here is to inspiration. .",
            "url": "https://leonardmutambanengwe.github.io/leonardblog/markdown/2018/06/21/Welcome.html",
            "relUrl": "/markdown/2018/06/21/Welcome.html",
            "date": " • Jun 21, 2018"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://leonardmutambanengwe.github.io/leonardblog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://leonardmutambanengwe.github.io/leonardblog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}