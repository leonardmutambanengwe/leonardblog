{
  
    
        "post0": {
            "title": "Title",
            "content": "Getting started with arrays in Julia using images . Following this Computational Thinking Course by MIT and JuliaImages and Tutorialspoint&#39;s Julia Tutorial . Julia has been touted as the next best thing in computational programming, potentially replacing fan favourite, Python, as the go to language for data science and machine learning. . https://twitter.com/JuliaLanguage/status/1477307810564169731 . I have been looking to learn Julia for some time, and have finally gathered the courage to begin, following the MIT&#39;s 2021 Computational Thinking course and Tutorialspoint tutorial. The hope is to use Julia for quantitative economics, agent-based models and related interests (and some data science and machine learning of course!). . Some introductory concepts like installation, environments, packages and variables I have skipped to dive into the language. The Tutorialspoint tutorial gives quite good explanations for these. . Arrays are key to computational work, providing the building blocks for programming work in data science and machine learning. In this piece, I will use images to explore arrays. An array in Julia is a set of items &quot;specified with square brackets&quot; that can contain similar items or different items. . Creating arrays... | arr = [1,2,3] . 3-element Vector{Int64}: 1 2 3 . arr1 = [&quot;Leonard&quot;, tan, RGB(0, 1, 1, 1.245)] . Array[1:10] . 1-element Vector{Array}: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] . arr2 = Array{Int64}(undef, 2, 2) #Create a 2x2 array with undefined values of type Integer64 . Array[1:5,5:9] . 2-element Vector{Array}: [1, 2, 3, 4, 5] [5, 6, 7, 8, 9] . collect(1:2:20) . 10-element Vector{Int64}: 1 3 5 7 9 11 13 15 17 19 . arr3 = collect(range(1, 15, 30)) . 30-element Vector{Float64}: 1.0 1.4827586206896552 1.9655172413793103 2.4482758620689653 2.9310344827586206 3.413793103448276 3.896551724137931 4.379310344827586 4.862068965517241 5.344827586206897 ⋮ 11.137931034482758 11.620689655172415 12.10344827586207 12.586206896551724 13.068965517241379 13.551724137931034 14.03448275862069 14.517241379310345 15.0 . Collect uses (start:step:stop) format whilst range uses (start, stop, length). . [1:10...] #using the ellipses . 10-element Vector{Int64}: 1 2 3 4 5 6 7 8 9 10 . A matrix can be created by specifying the arrays, separating the rows with a semi-colon (;) . matrix = [[1 2];[3 4]] . 2×2 Matrix{Int64}: 1 2 3 4 . Compare with.. . arr4 = [[1 2], [3 4]] . 2-element Vector{Matrix{Int64}}: [1 2] [3 4] . tensor = Array{Float32}(undef, 3, 3, 3) . 3×3×3 Array{Float32, 3}: [:, :, 1] = 0.0 0.0 4.0f-45 0.0 3.0f-45 0.0 1.0f-45 0.0 6.0f-45 [:, :, 2] = 0.0 7.0f-45 0.0 7.0f-45 0.0 1.0f-44 0.0 1.0f-44 0.0 [:, :, 3] = 1.3f-44 0.0 6.0f-45 0.0 1.5f-44 0.0 1.3f-44 0.0 1.8f-44 . Manipulating arrays.. | These functions change the array in place, nota bene. . push!(arr, 10) . 4-element Vector{Int64}: 1 2 3 10 . pushfirst!(arr, 27) . 5-element Vector{Int64}: 27 1 2 3 10 . splice!(arr, 3, 12) . 2 . pop!(arr) . Arrays with images | using Images #importing a package (use add Package to install the package) . path_to_image = &quot;.. images Brain-Teaser2.png&quot; img = load(path_to_image) . Julia, in the notebook automatically shows the read image. Cool! Also Julia strings are double quotes ONLY, nota bene. . size(img) . (578, 1255) . img[100, 200] . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; . RGB(0, 0, 1) . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; Another really cool feature from Julia. Can you do this in Python? . brain = img[100:470, 350:900] . save(&quot;.. images brain.png&quot;, brain) . All errors: =========================================== Could not open . imagesrain.png for writing =========================================== WriteBlob Failed `. imagesrain.png&#39; @ error/png.c/MagickPNGErrorHandler/1641 =========================================== SystemError: opening file &#34;. images brain.png&#34;: Invalid argument =========================================== . Errors encountered while save FileIO.File{FileIO.DataFormat{:PNG}, String}(&#34;. images brain.png&#34;). Fatal error: . 0 . The save function worked, but why it threw those errors, I am not sure yet. Errors in Julia I haven&#39;t yet grasped. Still yet to see a language with helpful error messages! . Kaleidoscope The last element of an array is &quot;end&quot; compared to -1 in python . [ img img[:, end:-1:1] img[end:-1:1,:] img[end:-1:1, end:-1:1] ] . size(pex) . (750, 1042) . imgc = rand(RGB{Base.Float32}, 3, 3) . dump(imgc) #dump gives the internal representation of an object . Array{RGB{Float32}}((3, 3)) 1: RGB{Float32} r: Float32 0.11253506f0 g: Float32 0.55760473f0 b: Float32 0.27864915f0 2: RGB{Float32} r: Float32 0.18111825f0 g: Float32 0.28725207f0 b: Float32 0.9795578f0 3: RGB{Float32} r: Float32 0.28679127f0 g: Float32 0.43194884f0 b: Float32 0.5378687f0 4: RGB{Float32} r: Float32 0.4753642f0 g: Float32 0.035165608f0 b: Float32 0.88715f0 5: RGB{Float32} r: Float32 0.4875096f0 g: Float32 0.20408314f0 b: Float32 0.01918888f0 6: RGB{Float32} r: Float32 0.18497908f0 g: Float32 0.1815986f0 b: Float32 0.276653f0 7: RGB{Float32} r: Float32 0.67196274f0 g: Float32 0.4420526f0 b: Float32 0.50409055f0 8: RGB{Float32} r: Float32 0.44515795f0 g: Float32 0.70845145f0 b: Float32 0.99803203f0 9: RGB{Float32} r: Float32 0.4571224f0 g: Float32 0.5548946f0 b: Float32 0.38366348f0 . imgc[2,3] . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; dump(imgc[2,3]) . RGB{Float32} r: Float32 0.44515795f0 g: Float32 0.70845145f0 b: Float32 0.99803203f0 . c = imgc[2,3]; (red(c), green(c), blue(c)) . (0.44515795f0, 0.99803203f0, 0.70845145f0) . [RGB(x, 1, 1) for x in 0:0.1:1.0] . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; [ RGB(x, y, 1) for x in 0:0.1:1.0, y in 0:0.1:1.0 ] . Other cool things in Julia to do with images. To be explored more in a later post. Mosaicview makes it easy to juxtapose images, or stack them. Rot180 and reverse are self explaining. . pex = load(&quot;./images/pexels-photo-2422290.jpeg&quot;) . mosaicview(img, pex) . mosaicview(img, pex; nrow=1) . rot180(img) . reverse(pex) . Synthetic images using random numbers | img_gen = randn(300, 250, 3) . 300×250×3 Array{Float64, 3}: [:, :, 1] = -0.600125 -1.56632 -0.312504 … -0.103091 -0.271007 -1.13409 0.244688 1.25623 0.259431 -0.636025 -0.208713 0.315366 -1.22143 -0.59499 0.604384 -0.116677 1.16373 -0.0722718 -0.622335 -1.08539 -0.724112 0.609908 -0.0189383 -0.128967 1.35767 1.31528 -0.249722 -1.36404 -0.293069 0.556582 0.534793 1.27606 -0.154081 … 1.12524 0.552972 1.02783 0.319008 0.00880301 0.220965 1.11737 0.779357 -0.309602 -0.362791 -1.31784 -0.253949 0.353058 -0.453932 -0.574562 -0.120969 -0.962137 1.34985 2.07872 -0.94339 -0.0697277 0.0511402 -1.99099 0.736905 1.61943 2.2774 -0.513229 ⋮ ⋱ -0.323872 -0.181434 1.12721 -1.13482 0.335018 0.868675 0.603353 -0.606318 0.939072 0.048147 0.316767 0.275852 0.977469 -1.24712 -1.44946 0.3013 -1.0562 -0.800215 2.2684 1.51708 0.621769 1.23412 0.656476 0.201373 -0.136838 0.634701 -0.215518 … -0.201611 -2.17347 1.6066 -1.24558 0.0652409 0.0804678 -0.854146 -0.578367 1.92466 2.00107 -0.596724 1.53221 1.57971 0.84556 -0.47681 -0.439637 -0.196832 -1.69774 -0.5361 -0.582335 1.0349 -0.304142 -0.622998 -1.41491 -0.600071 2.76946 0.676878 [:, :, 2] = -1.07388 -0.605201 -0.213867 … 0.853067 -0.291855 -2.45098 0.129474 -0.121532 1.2076 -0.0610356 -2.04145 0.00149836 1.27809 0.779509 0.640596 1.35758 0.450349 2.08358 0.0636016 1.07457 0.0605442 0.110871 -1.66489 1.3797 -0.244607 -0.307671 0.357756 -0.436152 0.438603 0.0740943 1.25962 0.742925 0.38487 … -0.720242 -0.586007 0.440213 -1.36131 1.45913 -1.26939 -0.3846 -0.570169 -0.0160573 0.754807 1.03674 -0.443173 0.468278 0.892556 -0.586991 -1.77824 0.839453 -1.48134 -1.22049 0.279893 1.58792 1.0486 0.604839 -0.161788 0.292014 -1.75065 0.67918 ⋮ ⋱ 1.94354 -1.4899 -0.300526 -2.11149 -0.536682 1.23141 -1.80439 -0.384776 -1.01934 -0.31576 -0.743674 -0.735456 -2.11735 -0.409913 -0.147772 0.604897 -0.416731 -0.3253 0.117426 -0.591422 -1.71241 -1.42072 1.67098 2.64896 -0.0323333 1.05344 -1.36912 … -0.0445616 -1.00345 1.59313 -0.265179 0.501541 -2.47764 -1.71942 -0.628153 0.0107511 0.630664 0.191456 0.291961 0.770989 0.470247 -0.239118 -0.0167329 -1.78455 -1.55999 -1.14523 -1.08318 -0.506993 -2.39033 -0.799303 -0.51274 0.0174815 -0.31149 0.127548 [:, :, 3] = 0.140216 -0.485375 0.267151 … -0.385111 2.16931 -0.353331 -0.561392 -0.841544 1.90666 -1.6451 0.416531 -0.564599 -0.0901542 0.617174 1.20817 -0.698607 -0.0417566 0.0464137 1.02936 0.509171 -1.35276 -1.0066 1.54414 -0.0431321 0.697595 0.639903 0.150722 0.468857 -1.11395 1.33858 -0.923934 0.232699 1.3056 … -0.142713 -1.5119 -0.223377 -0.989095 -0.255251 0.0348486 -0.721624 -2.00278 0.331685 -0.0124481 1.52724 1.43884 0.267863 1.34697 -1.29293 0.0802858 0.395102 -0.0679597 1.22957 -0.0325846 0.949232 -0.324235 0.555573 1.09 0.254719 1.37643 1.80199 ⋮ ⋱ 1.12088 0.120046 0.199124 -0.982841 -0.692224 -1.05452 0.312383 0.0519733 0.258929 0.843973 0.714431 -1.20695 -1.27403 -0.639111 -3.03254 -1.10927 0.723798 0.0525366 0.861625 -0.698227 -1.35669 1.3572 0.399639 -0.0544047 0.144619 0.807803 -0.733975 … -1.10102 -0.401426 0.574467 -0.203666 -0.848899 0.0437872 -0.637434 0.122017 -0.475935 -0.843858 0.189737 -0.0541529 -1.96681 1.76856 -0.518815 1.378 0.342705 1.2765 0.018891 0.833686 0.344957 -0.105764 -0.368011 0.23163 0.917879 0.243322 0.616008 . colorview(RGB, reshape(img_gen, 3, 300, 250)) . colorview(RGB, reshape(img_gen, (3, 250, 300))) .",
            "url": "https://leonardmutambanengwe.github.io/leonardblog/2022/01/03/Getting-Started-with-Arrays-in-Julia-with-Images.html",
            "relUrl": "/2022/01/03/Getting-Started-with-Arrays-in-Julia-with-Images.html",
            "date": " • Jan 3, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "A Logistic Regression model using the Breast Cancer dataset",
            "content": "Introduction to Logistic Regression . Used when we have to choose between 2 values, in this case choosing between malignant and benign. The regression produces an S shape graph assumptions of logistic regression: . There should not be any multi_collinearity in the model, which means the features must be independent of each other. | We must include meaningful variables in our model | We should choose a lage sample size for our logisitic regression | . Solvers -&gt; liblinear =&gt; is for multiclass classifiers . from sklearn.datasets import load_breast_cancer import pandas as pd from sklearn.linear_model import LogisticRegression from sklearn.model_selection import train_test_split from sklearn.metrics import roc_curve import matplotlib.pyplot as plt # Determines how many columns should be displayed on the output data pd.options.display.max_columns = 30 . Load the dataset, which comes with Scikit Learn and explore information about the data . breast_cancer_dataset = load_breast_cancer() breast_cancer = pd.DataFrame(breast_cancer_dataset.data, columns=breast_cancer_dataset.feature_names) breast_cancer[&#39;result&#39;] = breast_cancer_dataset[&#39;target&#39;] # Give a detailed description of the dataset print(breast_cancer_dataset.keys()) print(breast_cancer_dataset[&#39;DESCR&#39;]) . dict_keys([&#39;data&#39;, &#39;target&#39;, &#39;frame&#39;, &#39;target_names&#39;, &#39;DESCR&#39;, &#39;feature_names&#39;, &#39;filename&#39;]) .. _breast_cancer_dataset: Breast cancer wisconsin (diagnostic) dataset -- **Data Set Characteristics:** :Number of Instances: 569 :Number of Attributes: 30 numeric, predictive attributes and the class :Attribute Information: - radius (mean of distances from center to points on the perimeter) - texture (standard deviation of gray-scale values) - perimeter - area - smoothness (local variation in radius lengths) - compactness (perimeter^2 / area - 1.0) - concavity (severity of concave portions of the contour) - concave points (number of concave portions of the contour) - symmetry - fractal dimension (&#34;coastline approximation&#34; - 1) The mean, standard error, and &#34;worst&#34; or largest (mean of the three worst/largest values) of these features were computed for each image, resulting in 30 features. For instance, field 0 is Mean Radius, field 10 is Radius SE, field 20 is Worst Radius. - class: - WDBC-Malignant - WDBC-Benign :Summary Statistics: ===================================== ====== ====== Min Max ===================================== ====== ====== radius (mean): 6.981 28.11 texture (mean): 9.71 39.28 perimeter (mean): 43.79 188.5 area (mean): 143.5 2501.0 smoothness (mean): 0.053 0.163 compactness (mean): 0.019 0.345 concavity (mean): 0.0 0.427 concave points (mean): 0.0 0.201 symmetry (mean): 0.106 0.304 fractal dimension (mean): 0.05 0.097 radius (standard error): 0.112 2.873 texture (standard error): 0.36 4.885 perimeter (standard error): 0.757 21.98 area (standard error): 6.802 542.2 smoothness (standard error): 0.002 0.031 compactness (standard error): 0.002 0.135 concavity (standard error): 0.0 0.396 concave points (standard error): 0.0 0.053 symmetry (standard error): 0.008 0.079 fractal dimension (standard error): 0.001 0.03 radius (worst): 7.93 36.04 texture (worst): 12.02 49.54 perimeter (worst): 50.41 251.2 area (worst): 185.2 4254.0 smoothness (worst): 0.071 0.223 compactness (worst): 0.027 1.058 concavity (worst): 0.0 1.252 concave points (worst): 0.0 0.291 symmetry (worst): 0.156 0.664 fractal dimension (worst): 0.055 0.208 ===================================== ====== ====== :Missing Attribute Values: None :Class Distribution: 212 - Malignant, 357 - Benign :Creator: Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian :Donor: Nick Street :Date: November, 1995 This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets. https://goo.gl/U2Uwz2 Features are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass. They describe characteristics of the cell nuclei present in the image. Separating plane described above was obtained using Multisurface Method-Tree (MSM-T) [K. P. Bennett, &#34;Decision Tree Construction Via Linear Programming.&#34; Proceedings of the 4th Midwest Artificial Intelligence and Cognitive Science Society, pp. 97-101, 1992], a classification method which uses linear programming to construct a decision tree. Relevant features were selected using an exhaustive search in the space of 1-4 features and 1-3 separating planes. The actual linear program used to obtain the separating plane in the 3-dimensional space is that described in: [K. P. Bennett and O. L. Mangasarian: &#34;Robust Linear Programming Discrimination of Two Linearly Inseparable Sets&#34;, Optimization Methods and Software 1, 1992, 23-34]. This database is also available through the UW CS ftp server: ftp ftp.cs.wisc.edu cd math-prog/cpo-dataset/machine-learn/WDBC/ .. topic:: References - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction for breast tumor diagnosis. IS&amp;T/SPIE 1993 International Symposium on Electronic Imaging: Science and Technology, volume 1905, pages 861-870, San Jose, CA, 1993. - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and prognosis via linear programming. Operations Research, 43(4), pages 570-577, July-August 1995. - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) 163-171. . In order to know what the target set represents, output is -&gt; [&#39;malignant&#39; &#39;benign&#39;] showing that a 0=&gt;malignant and 1=&gt;benign . print(breast_cancer_dataset[&#39;target_names&#39;]) . [&#39;malignant&#39; &#39;benign&#39;] . Exploration of features.. . breast_cancer.describe() . mean radius mean texture mean perimeter mean area mean smoothness mean compactness mean concavity mean concave points mean symmetry mean fractal dimension radius error texture error perimeter error area error smoothness error ... concavity error concave points error symmetry error fractal dimension error worst radius worst texture worst perimeter worst area worst smoothness worst compactness worst concavity worst concave points worst symmetry worst fractal dimension result . count 569.000000 | 569.000000 | 569.000000 | 569.000000 | 569.000000 | 569.000000 | 569.000000 | 569.000000 | 569.000000 | 569.000000 | 569.000000 | 569.000000 | 569.000000 | 569.000000 | 569.000000 | ... | 569.000000 | 569.000000 | 569.000000 | 569.000000 | 569.000000 | 569.000000 | 569.000000 | 569.000000 | 569.000000 | 569.000000 | 569.000000 | 569.000000 | 569.000000 | 569.000000 | 569.000000 | . mean 14.127292 | 19.289649 | 91.969033 | 654.889104 | 0.096360 | 0.104341 | 0.088799 | 0.048919 | 0.181162 | 0.062798 | 0.405172 | 1.216853 | 2.866059 | 40.337079 | 0.007041 | ... | 0.031894 | 0.011796 | 0.020542 | 0.003795 | 16.269190 | 25.677223 | 107.261213 | 880.583128 | 0.132369 | 0.254265 | 0.272188 | 0.114606 | 0.290076 | 0.083946 | 0.627417 | . std 3.524049 | 4.301036 | 24.298981 | 351.914129 | 0.014064 | 0.052813 | 0.079720 | 0.038803 | 0.027414 | 0.007060 | 0.277313 | 0.551648 | 2.021855 | 45.491006 | 0.003003 | ... | 0.030186 | 0.006170 | 0.008266 | 0.002646 | 4.833242 | 6.146258 | 33.602542 | 569.356993 | 0.022832 | 0.157336 | 0.208624 | 0.065732 | 0.061867 | 0.018061 | 0.483918 | . min 6.981000 | 9.710000 | 43.790000 | 143.500000 | 0.052630 | 0.019380 | 0.000000 | 0.000000 | 0.106000 | 0.049960 | 0.111500 | 0.360200 | 0.757000 | 6.802000 | 0.001713 | ... | 0.000000 | 0.000000 | 0.007882 | 0.000895 | 7.930000 | 12.020000 | 50.410000 | 185.200000 | 0.071170 | 0.027290 | 0.000000 | 0.000000 | 0.156500 | 0.055040 | 0.000000 | . 25% 11.700000 | 16.170000 | 75.170000 | 420.300000 | 0.086370 | 0.064920 | 0.029560 | 0.020310 | 0.161900 | 0.057700 | 0.232400 | 0.833900 | 1.606000 | 17.850000 | 0.005169 | ... | 0.015090 | 0.007638 | 0.015160 | 0.002248 | 13.010000 | 21.080000 | 84.110000 | 515.300000 | 0.116600 | 0.147200 | 0.114500 | 0.064930 | 0.250400 | 0.071460 | 0.000000 | . 50% 13.370000 | 18.840000 | 86.240000 | 551.100000 | 0.095870 | 0.092630 | 0.061540 | 0.033500 | 0.179200 | 0.061540 | 0.324200 | 1.108000 | 2.287000 | 24.530000 | 0.006380 | ... | 0.025890 | 0.010930 | 0.018730 | 0.003187 | 14.970000 | 25.410000 | 97.660000 | 686.500000 | 0.131300 | 0.211900 | 0.226700 | 0.099930 | 0.282200 | 0.080040 | 1.000000 | . 75% 15.780000 | 21.800000 | 104.100000 | 782.700000 | 0.105300 | 0.130400 | 0.130700 | 0.074000 | 0.195700 | 0.066120 | 0.478900 | 1.474000 | 3.357000 | 45.190000 | 0.008146 | ... | 0.042050 | 0.014710 | 0.023480 | 0.004558 | 18.790000 | 29.720000 | 125.400000 | 1084.000000 | 0.146000 | 0.339100 | 0.382900 | 0.161400 | 0.317900 | 0.092080 | 1.000000 | . max 28.110000 | 39.280000 | 188.500000 | 2501.000000 | 0.163400 | 0.345400 | 0.426800 | 0.201200 | 0.304000 | 0.097440 | 2.873000 | 4.885000 | 21.980000 | 542.200000 | 0.031130 | ... | 0.396000 | 0.052790 | 0.078950 | 0.029840 | 36.040000 | 49.540000 | 251.200000 | 4254.000000 | 0.222600 | 1.058000 | 1.252000 | 0.291000 | 0.663800 | 0.207500 | 1.000000 | . 8 rows × 31 columns . breast_cancer.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 569 entries, 0 to 568 Data columns (total 31 columns): # Column Non-Null Count Dtype -- -- 0 mean radius 569 non-null float64 1 mean texture 569 non-null float64 2 mean perimeter 569 non-null float64 3 mean area 569 non-null float64 4 mean smoothness 569 non-null float64 5 mean compactness 569 non-null float64 6 mean concavity 569 non-null float64 7 mean concave points 569 non-null float64 8 mean symmetry 569 non-null float64 9 mean fractal dimension 569 non-null float64 10 radius error 569 non-null float64 11 texture error 569 non-null float64 12 perimeter error 569 non-null float64 13 area error 569 non-null float64 14 smoothness error 569 non-null float64 15 compactness error 569 non-null float64 16 concavity error 569 non-null float64 17 concave points error 569 non-null float64 18 symmetry error 569 non-null float64 19 fractal dimension error 569 non-null float64 20 worst radius 569 non-null float64 21 worst texture 569 non-null float64 22 worst perimeter 569 non-null float64 23 worst area 569 non-null float64 24 worst smoothness 569 non-null float64 25 worst compactness 569 non-null float64 26 worst concavity 569 non-null float64 27 worst concave points 569 non-null float64 28 worst symmetry 569 non-null float64 29 worst fractal dimension 569 non-null float64 30 result 569 non-null int32 dtypes: float64(30), int32(1) memory usage: 135.7 KB . The dataset does not include any null or missing values so there won&#39;t be any need for data wrangling (dealing with missing values). . X = breast_cancer.values y = breast_cancer[&#39;result&#39;].values . It is also possible to instantiate X and y without .values (.values changes the Dataframe to a numpy array) . For good training and testing the dataset, we should split our data. We are going to split our data into 70% training size and 30% test size. It&#39;s more convenient to test our dataset with the small portion of the dataset, but it shouldn&#39;t be too small. . X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.7, random_state=1) model = LogisticRegression(solver=&#39;liblinear&#39;) model.fit(X_train, y_train) . LogisticRegression(solver=&#39;liblinear&#39;) . If we try to fit using the default solver, we get a convergence warning meaning the model needs more time to find the optimal solution, This can be solved by using a different solver. In this instance we shall use the &#39;liblinear&#39; solver. . y_pred = model.predict(X_test) . from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score # each function takes two 1-dimensional numpy arrays: the true values and the predicted values of the target print(&quot;accuracy: &quot;, accuracy_score(y_test, y_pred)) print(&quot;precision: &quot;, precision_score(y_test, y_pred)) print(&quot;recall: &quot;, recall_score(y_test, y_pred)) print(&quot;f1_score: &quot;, f1_score(y_test, y_pred)) # using scikit-learn we are able to get the four values in the confusion matrix from sklearn.metrics import confusion_matrix print(confusion_matrix(y_test, y_pred)) . accuracy: 0.9624060150375939 precision: 0.95703125 recall: 0.9839357429718876 f1_score: 0.9702970297029703 [[139 11] [ 4 245]] . All of the metric calculations show good scores which means that our Logistic Regression model is good . # USING ROC CURVE # . An ROC curve (receiver operating characteristic curve) is a graph showing the performance of a classification model at all classification thresholds. The ROC curve is a graph of the specificity vs sensitivity i.e specificity is the % actual negatives correctly predicted and sensitivity being the % actual positives correctly predicted. . y_pred_proba = model.predict_proba(X_test) fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba[:, 1]) plt.plot(fpr, tpr) plt.plot([0, 1], [0, 1], linestyle=&#39;--&#39;) # plt.xlim(0.0, 1.0) # plt.ylim(0.0, 1.0) plt.xlabel(&#39;1 - specificity&#39;) plt.ylabel(&#39;sensitivity&#39;) plt.show() .",
            "url": "https://leonardmutambanengwe.github.io/leonardblog/2021/07/01/Logistic-Regression-using-Breast-Cancer-dataset.html",
            "relUrl": "/2021/07/01/Logistic-Regression-using-Breast-Cancer-dataset.html",
            "date": " • Jul 1, 2021"
        }
        
    
  
    
        ,"post2": {
            "title": "Filling the void",
            "content": "Looking out of the window, on a moody January morning, it is hard to tell how I got here. It is 2021, and it seems the hopes for a better 2021 have not started to bear fruit, with the pandemic raging more than ever, outisde in the world. Infections and deaths are up, many countries hitting record highs, eclipsing the first wave figures. But life has to go on. We live day by day. . It has been a good 2+ years since I have written anything, and this post, as titled, is to fill that gap and give a perspective on the road ahead. I guess it also refers to the perspective itself. I feel this an effort to rise to some occassion, and that I can only do by admitting that I had lost my way, somewhere along the road. . I remember, 2018 felt great. Completed my qualification, spoke at my first conference, constituted Data Science Zimbabwe and we had our first meet up and I was looking forward to taking my first real venture, Peachgrove, an horticultural produce and marketing venture, off the ground. Everything felt good. The sky was the limit. But Zimbabwe is not an easy country, and the hope of the reset in 2017 (despite the same honchos still running the country) faded and all illusions disappeared quite fast. Having to build up and get things running in a volatile environment meant the horticultural venture would really not translate to anything except lessons. Lessons that will be valuable in anything I attempt going forward and still one day, I certainly hope to explore the venture, to start again, for I feel it is a part of my being. . Along the road, another venture came up. Quantum Analytica, a data analytics-marketing-systems development outfit. The prospects looked great. We had initial contact with multiple clients, the appetite for our services seemed bottomless. The discussions were amazing, the founding team even more so. But maybe because I was still holding on to Peachgrove, hoping that I can find a way out of the malaise it was suffering, and Quantum Analytica seemed to be able to play a role in that. But it also fell apart. The environment in Zimbabwe has impacted a lot of things for entrepreneurs. The volatility impacting the effectiveness of any resources, but nothing is more poignant than the impact on the people resources. It becomes to hard to get people to buy in into any entrepreneurial venture. It definitely is not unexpected given the situation. It still makes it hard. And so we found ourselves having to shelf a good opportunity. And I went back to farming… . All the while, Data Science Zimbabwe has been chugging along, quietly in the background. DSZ was created as a means to provide a platform to bring together Zimbabweans interested in data and data-based solutions together. And we managed to get the interest going in a short time. I am so grateful to the community for making up a vibrant community. Operating on a zero revenue budget, there has been more done within the organization that I could have thought in 2018, beginning the journey. And it has been my ray of hope, as everything else seemed untenable, the prospect of making an impact is very humbling and satisfying. And even in 2020 when the pandemic threatened everything else, the community kept on, engaging over Whatsapp, participating in hackathons, and I can definitely say for the near future, it is my main consideration and I hope 2021 sees the community grow in leaps and bounds, and initiatives lead to visibility for the community at the forefront of the 4th Industrial Revolution in Zimbabwe. . So 2021 is here. And the hope is that for the lessons learnt in the past 2 years, and the new normal that is being hashed out by the pandemic, resilience and taking care of opportunities that present themselves are the order of the day to fill that void and get back to the unfettered hope that coursed these veins in 2018. . Let’s go!!!! I am up for it. .",
            "url": "https://leonardmutambanengwe.github.io/leonardblog/2021/01/14/Filling-the-void.html",
            "relUrl": "/2021/01/14/Filling-the-void.html",
            "date": " • Jan 14, 2021"
        }
        
    
  
    
        ,"post3": {
            "title": "Back to Africa ..and of conferences and travel documents",
            "content": "So I have been back from Italy for close to 75 days now, and it has mostly been chilling, watching television and catching up with family. I have also put in a number of applications with some local companies for data science jobs and had a grand total of ZERO responses. My closest bet at the moment is a company that does not know whether to put me under IT or Finance departments. But that is the situation in South Africa currently, with the onset of economic problems and perennial youth unemployment. Worse still, I am Zimbabwean in South Africa, job issues are always to be expected. So what to do? . In February 2018 I, with others, started a group called Data Science Zimbabwe that we hope can be a platform for people in data-related professions and academia to lead the 4th Industrial Revolution in Zimbabwe. We have only so far communicated via WhatsApp, but I am hopeful of the prospects. I am hoping we can have our first meet-up soon and start putting together a solid foundation for the advancement of data science and machine and deep learning as well as Artificial Intelligence in Zimbabwe. So for the time being, that is what my data science path has led me to and I am relishing the challenge. . I have also done a talk proposal for PyCon Zimbabwe on Agent-based modeling and Network Analysis using MESA and NetworkX, hopefully the experience is positive and provides an opportunity to make Data Science Zimbabwe visible within the tech community. This leads me to an important topic, that impacted me personally and have seen general discussions about on social media as well, globally. The choice of venues for conferences. . The Deep Learning Indaba was set for Stellenbosch University in South Africa. This is an important conference, in terms of my field and is important that participation, especially from Africans, show that the field is alive and kicking on the continent. However, South Africa is one of the hardest countries to get immigration documents for on the continent, especially to fellow Africans. I know the topic of holding conferences in countries that are inclusive is not new, and has gained traction in light of the trends in geopolitics in Europe and America. And here in Africa it is of no less concern. I was heartbroken when I saw a tweet about someone who had been given the whole funding to attend the conference, on condition they got their documents for travel to South Africa sorted out. No prize for guessing the outcome of their application. . Is Africa ready for full on co-operation in cutting edge fields that transcends borders? Can we get the academics, practitioners, experts etc in the same room, without hassle about movement from country A to country B? Should these types of conferences, be it in our field or any other, be held in countries that make it hard for those from other countries to travel there and be a part of these important get-togethers. These are the kind of matters that will affect Africa’s ability to embrace advancements in any area and be able to build lasting solutions to problems on our continent. I feel sorry for anyone who would have wanted to attend this conference and has to live with Twitter updates and Github practicals. . Rwanda has done Africa a solid with their changes to requirements for travel to the country, for Africans. This is a move to be applauded. But at this moment, I would tip my hat to any country on the continent that will suspend its (obviously) rigid, red tape surrounding movement for academic or professional conferences and gatherings and get-togethers, because if Africa is going to progress, we need to have great minds together as frequently as possible. This will help create networks all over the continent, not hindered by the travel requirements and a solid hope for the getting a lot of work done and catching up to global levels of progress in many fields. . I hope one day Africa will not let colonial demarcations hamper the progress of its people, and we will see the free flow of knowledge from Cape to Cairo. .",
            "url": "https://leonardmutambanengwe.github.io/leonardblog/2018/09/14/Back-to-Africa-/and-of-conferences-and-travel-documents.html",
            "relUrl": "/2018/09/14/Back-to-Africa-/and-of-conferences-and-travel-documents.html",
            "date": " • Sep 14, 2018"
        }
        
    
  
    
        ,"post4": {
            "title": "Welcome!",
            "content": "This is a log of activities and expected for the year commencing from my return to the Motherland. I hope I can look at it in one year and make an informed decision about the next steps I want to take. It will also have, general blog posts, on matters of interest, especially techpreneurship and general economics commentary. So here is to inspiration. .",
            "url": "https://leonardmutambanengwe.github.io/leonardblog/markdown/2018/06/21/Welcome.html",
            "relUrl": "/markdown/2018/06/21/Welcome.html",
            "date": " • Jun 21, 2018"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://leonardmutambanengwe.github.io/leonardblog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://leonardmutambanengwe.github.io/leonardblog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}